{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "experienced-reviewer",
   "metadata": {},
   "source": [
    "# Decoding stimulus identity from neural responses\n",
    "\n",
    "We implement here a nearest-neighbor decoder of neural activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "weighted-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general modules\n",
    "import pynwb, os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# custom modules\n",
    "sys.path.append('..')\n",
    "from physion.dataviz.show_data import MultimodalData, EpisodeResponse\n",
    "from datavyz import graph_env_manuscript as ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b890dcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NWB-file reading time: 176.2ms\n",
      "  Number of episodes over the whole recording: 210/240 (with protocol condition)\n",
      "  building episodes with 3 modalities [...]\n",
      "\n",
      "calculating dF/F with method \"maximin\" [...]\n",
      "\n",
      "  ** 24 ROIs were discarded with the positive F0 criterion (5.6%) ** \n",
      "\n",
      "-> dFoF calculus done !  (calculation took 0.9s)\n",
      "  -> [ok] episodes ready !\n",
      "{'Image-ID': array([0., 1., 2., 3., 4., 5.]), 'VSE-seed': array([3., 4.]), 'repeat': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17], dtype=int32)}\n",
      "['dFoF']\n"
     ]
    }
   ],
   "source": [
    "filename = '/home/yann.zerlaut/DATA/curated/2022_03_07-15-31-56.nwb'\n",
    "episodes = EpisodeResponse(filename, quantities=['dFoF', 'rawFluo', 'pupil'], verbose=True)\n",
    "print(episodes.varied_parameters)\n",
    "print(episodes.quantities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e88dc981",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/yann.zerlaut/miniconda3/envs/physion/lib/python3.7/site-packages/physion/visual_stim/NI_bank'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3418901/1013424397.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepisodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepisode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m episodes.plot_evoked_pattern(episodes.find_episode_cond(['Image-ID', 'VSE-seed'], [0,0]),\n\u001b[0;32m----> 3\u001b[0;31m                              quantity='dFoF')\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/physion/lib/python3.7/site-packages/physion/dataviz/show_data.py\u001b[0m in \u001b[0;36mplot_evoked_pattern\u001b[0;34m(self, pattern_cond, quantity, rois, with_stim_inset, with_mean_trace, factor_for_traces, raster_norm, Tbar, Nbar, min_dFof_range, figsize)\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwith_stim_inset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisual_stim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_visual_stim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m             \u001b[0mstim_inset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisual_stim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_stim_picture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstim_inset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menhance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/physion/lib/python3.7/site-packages/physion/dataviz/show_data.py\u001b[0m in \u001b[0;36minit_visual_stim\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_visual_stim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'load_from_protocol_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'no-window'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisual_stim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_stim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_psychopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m###-------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/physion/lib/python3.7/site-packages/physion/visual_stim/psychopy_code/stimuli.py\u001b[0m in \u001b[0;36mbuild_stim\u001b[0;34m(protocol, no_psychopy)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnatural_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Stimulus'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'Natural-Image+VSE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnatural_image_vse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Stimulus'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'line-moving-dots'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mline_moving_dots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/physion/lib/python3.7/site-packages/physion/visual_stim/psychopy_code/stimuli.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, protocol)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0;31m# initializing set of NI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNIarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNI_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNI_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0mnew_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapt_to_screen_resolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/yann.zerlaut/miniconda3/envs/physion/lib/python3.7/site-packages/physion/visual_stim/NI_bank'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 167.301x272.976 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "episodes = episode\n",
    "episodes.plot_evoked_pattern(episodes.find_episode_cond(['Image-ID', 'VSE-seed'], [0,0]),\n",
    "                             quantity='dFoF')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e386bfd1",
   "metadata": {},
   "source": [
    "### find significantly responding neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d13cc1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dFoF']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        summary_data = episode.compute_summary_data(dict(interval_pre=[-1,0], interval_post=[1,2], test='wilcoxon', positive=True),\n",
    "                                                    response_args={'quantity':'dFoF', 'roiIndex':2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7097ef40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode.find_episode_cond(['Image-ID', 'VSE-seed'], [0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebb91ed1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EpisodeResponse' object has no attribute 'rawFluo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3408891/3701791573.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m fig = plot_evoked_pattern(episode, \n\u001b[0;32m---> 35\u001b[0;31m                           episode.find_episode_cond(['Image-ID', 'VSE-seed'], [0,0]))\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_3408891/3701791573.py\u001b[0m in \u001b[0;36mplot_evoked_pattern\u001b[0;34m(self, pattern_cond, quantity, rois)\u001b[0m\n\u001b[1;32m      4\u001b[0m                         rois=np.arange(5)):\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mresp\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EpisodeResponse' object has no attribute 'rawFluo'"
     ]
    }
   ],
   "source": [
    "def plot_evoked_pattern(self, \n",
    "                        pattern_cond, \n",
    "                        quantity='rawFluo',\n",
    "                        rois=np.arange(5)):\n",
    "    \n",
    "    resp = np.array(getattr(self, quantity))\n",
    "    print(np.mean(resp), np.min(resp))\n",
    "    resp -= resp.min(axis=(0,2)).reshape(1,resp.shape[1],1)\n",
    "    print(np.mean(resp))\n",
    "    fig, [axR, axT] = ge.figure(axes_extents=[[[1,3]],\n",
    "                                      [[1,4]]], \n",
    "                                figsize=(1.3,.3))\n",
    "    \n",
    "    # raster\n",
    "    axR.imshow(resp[pattern_cond,:,:].mean(axis=0),\n",
    "               cmap=ge.binary,\n",
    "               aspect='auto', interpolation='none',\n",
    "               #vmin=0, vmax=1, \n",
    "               #origin='lower',\n",
    "               extent = (self.t[0], self.t[-1],\n",
    "                         0, resp.shape[1]))\n",
    "\n",
    "    ge.set_plot(axR, [], xlim=[self.t[0], self.t[-1]])\n",
    "    \n",
    "    for r in rois:\n",
    "        shift = 4*r\n",
    "        ge.plot(episode.t, shift+resp[pattern_cond, r, :].mean(axis=0), \n",
    "                sy=resp[pattern_cond, r, :].std(axis=0),ax=axT, no_set=True)\n",
    "        for iep in range(np.sum(pattern_cond)):\n",
    "            axT.plot(episode.t, shift+resp[pattern_cond, r, :][iep,:], color=ge.tab10(iep), lw=.5)\n",
    "    ge.set_plot(axT, [], xlim=[self.t[0], self.t[-1]])\n",
    "    \n",
    "    return fig\n",
    "fig = plot_evoked_pattern(episode, \n",
    "                          episode.find_episode_cond(['Image-ID', 'VSE-seed'], [0,0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b84a7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatternResponses(Data):\n",
    "    \"\"\"\n",
    "    # inherited from the general Data class\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data,\n",
    "                 protocol_id=0,\n",
    "                 quantity='CaImaging', \n",
    "                 subquantity='Fluorescence',\n",
    "                 nmax_ROI = 10000, # to limit the number of ROIs\n",
    "                 build_dFoF_args={method_for_F0='maximin', sliding_window=60},\n",
    "                 verbose=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        if subquantity in ['dFoF', 'dF/F']:\n",
    "            \n",
    "        data.CaImaging_key, EPISODES = subquantity, []\n",
    "        # looping over cells, we get the episode responses\n",
    "        for roi in range(np.sum(data.iscell))[:nmax_ROI]:\n",
    "            data.roiIndices = [roi] \n",
    "            EPISODES.append(build_episodes(data, protocol_id=protocol_id,\n",
    "                                           quantity=quantity, verbose=False))\n",
    "        # now looping over conditions to build the pattern responses\n",
    "        KEYS = data.varied_parameters.keys()\n",
    "        VALUES = [v.flatten() for v in np.meshgrid(*[data.varied_parameters[k] for k in KEYS])]\n",
    "        STIM = {}\n",
    "        setattr(self, 'resp', [])\n",
    "        for key in KEYS:\n",
    "            STIM[key] = []\n",
    "        for i in range(len(VALUES[0])):\n",
    "            # looping over unique stimuli\n",
    "            cond = np.ones(len(EPISODES[0]['resp']), dtype=bool)\n",
    "            for key, values in zip(KEYS, VALUES):\n",
    "                cond = cond & (EPISODES[0][key]==values[i])\n",
    "                STIM[key].append(values[i])\n",
    "            # now building the set of repeated pattern for a unique stim\n",
    "            for icond in np.arange(len(EPISODES[0]['resp']))[cond]:\n",
    "                pattern = np.zeros((len(EPISODES), len(EPISODES[0]['resp'][0]))) # shape (ROI, time)\n",
    "                for roi, episodes in enumerate(EPISODES):\n",
    "                    pattern[roi,:] = episodes['resp'][icond]\n",
    "                getattr(self, 'resp').append(pattern)\n",
    "        setattr(self, 'stim', STIM)\n",
    "        setattr(self, 't', EPISODES[0]['t']) # time array corresponding to the patterns\n",
    "\n",
    "filename = os.path.join(os.path.expanduser('~'), 'DATA', 'Wild_Type', '2021_03_19-14-51-17.nwb')\n",
    "data = Data(filename)\n",
    "patterns = PatternResponses(data, protocol_id=2,\n",
    "                            quantity='CaImaging', \n",
    "                            subquantity='dF/F',\n",
    "                            nmax_ROI=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pattern(self, i, ax=None, tlim=None, Tsubsampling=10, \n",
    "                 annotations = dict(Tbar=1, Rbar=5), space=0.03, rm_annot=False):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, figsize=(3,1.8))\n",
    "    if tlim is None:\n",
    "        tlim = [self.t[0], self.t[-1]]\n",
    "    dT, dN = (tlim[1]-tlim[0]), self.resp[i].shape[0]\n",
    "    ax.imshow(self.resp[i][:,::Tsubsampling], cmap=plt.cm.binary,\n",
    "              aspect='auto', interpolation='none', vmin=0, vmax=10, origin='lower',\n",
    "              extent = (*tlim, 0, dN))\n",
    "    if (annotations is not None) and not rm_annot:\n",
    "        ax.plot([tlim[0]-space*dT, tlim[0]-space*dT+annotations['Tbar']], np.ones(2)*dN*(1+space), 'k')\n",
    "        ax.annotate('%ss' % annotations['Tbar'], (tlim[0]-space*dT, dN*(1+space)))\n",
    "        ax.plot(tlim[0]*np.ones(2)-space*dT, -annotations['Rbar']*np.arange(2)+dN*(1+space), 'k')\n",
    "        ax.annotate('%scells' % annotations['Rbar'], (tlim[0]-space*dT, dN*(1+space)), va='top', ha='right', rotation=90)\n",
    "        \n",
    "    ax.set_xlim([tlim[0]-2*space*dT, tlim[1]])\n",
    "    ax.set_ylim([0, (1+2*space)*dN])\n",
    "    ax.axis('off')\n",
    "    return ax\n",
    "\n",
    "fig, AX = plt.subplots(10, 5, figsize=(15,15))\n",
    "plt.subplots_adjust(top=.95, left=.02, right=1., bottom=0.)\n",
    "IDS = np.arange(1,6)\n",
    "for ii, ID in enumerate(IDS):\n",
    "    cond = (np.array(patterns.stim['Image-ID'])==ID) & (np.array(patterns.stim['VSE-seed'])==1.)\n",
    "    axi = AX[0][ii].inset_axes([0.5, 0.99, 0.4, 0.3])\n",
    "    \n",
    "    data.visual_stim.show_frame(np.argwhere((data.nwbfile.stimulus['Image-ID'].data[:]==ID))[0][0],\n",
    "                                    ax=axi, label=None)\n",
    "    \n",
    "    for ir, i in enumerate(np.arange(len(patterns.stim['repeat']))[cond]):\n",
    "        show_pattern(patterns, i, tlim=[-1,8], rm_annot=(ir>0), ax=AX[ir][ID-1])\n",
    "        if ID==1:\n",
    "            AX[ir][ID-1].annotate('trial#%i' % (ir+1), (AX[ir][0].get_xlim()[0], 0), ha='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-submission",
   "metadata": {},
   "source": [
    "## Defining a distance metrics for CaImaging responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rental-queensland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Distance(Pattern1, Pattern2):\n",
    "    \"\"\"\n",
    "    should have the shape (ROI, time)\n",
    "    \"\"\"\n",
    "    return np.sum((Pattern1-Pattern2)**2)\n",
    "\n",
    "X1 = np.ones((3,10))\n",
    "X2 = np.zeros((3,10))\n",
    "\n",
    "\n",
    "Distance(X2,X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-navigator",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
